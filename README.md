# 10-701 Project

## Project Proposal Rubric
*  [NIPS format](https://nips.cc/Conferences/2017/PaperInformation/StyleFiles) (one page excluding references, no abstract needed)  
*  A well-stated problem that you plan to explore  
*  The motivation behind this problem  
*  Relevant prior work (or similar work), if any  
*  Your proposed idea/method/approach  
*  How do you plan to implement your approach (e.g. for deep learning, tensorflow/pytorch/...?)  
*  A timeline of this project (just give an estimate), and what dataset you plan to use  


## Potential Project Ideas

---

* Compound Figure Separation  
  _(deep learning)_ _(convolutional neural networks)_  
  _(implementation)_  
  [Compound Figure Separation using CNN (website)](https://arxiv.org/abs/1703.05105)  
  [Compound Figure Separation (paper)](http://ceur-ws.org/Vol-1391/25-CR.pdf)  
  [Crowdsourcing for Compound Figure Annotation (paper)](https://lhncbc.nlm.nih.gov/system/files/pub9437.pdf)  
  [ImageCLEFmed 2016 (dataset)](http://www.imageclef.org/2016/medical)  
  [ImageCLEFmed 2015 (dataset)](http://www.imageclef.org/2015/medical)  
  
* Transfer Learning   
  [Overcoming Data Scarcity with Transfer Learning (website)](https://arxiv.org/abs/1711.05099)  

*  Causality  
   _(experimental design)_  _(selection on unobservables)_  _(counterfactual prediction)_
   _(deep learning)_  
   _(implementation)_  
   [DeepIV: Counterfactual Prediction using Instrument Variables (website)](http://proceedings.mlr.press/v70/hartford17a.html)  
   [DeepIV: Counterfactual Prediction using Instrument Variables (repo)](https://github.com/jhartford/DeepIV)  
   [A Minimax Surrogate Loss Approach to Causal Inference (paper)](http://web.mit.edu/stgoh/www/mypage/causalwebsite.pdf)  

*  Information Retrieval  
   _(probabilistic graphical models)_  
   _(implementation)_  
   [Credibility Analysis (website)](https://arxiv.org/abs/1707.08309)  
   [Latent Credibility Analysis (website)](https://experts.illinois.edu/en/publications/latent-credibility-analysis)  
   [Information Credibility (website)](https://link.springer.com/chapter/10.1007/978-3-319-29175-8_12)  
   [Dissertation (website)](https://smartech.gatech.edu/handle/1853/55646)  

*  Infinitely differentiable loss function [(Monte Carlo Estimator)](https://en.wikipedia.org/wiki/Monte_Carlo_method)  
   _(optimization)_  _(deep learning)_ _(reinforcement learning)_  
   _(implementation)_  
   [DiCE: The Infinitely Differentiable Monte Carlo Estimator (website)](https://arxiv.org/abs/1802.05098)  

*  Automatic generation of [surrogate loss functions](https://stats.stackexchange.com/a/267509/147296) given non-differentiable loss functions ([ACKTR, A2C](https://blog.openai.com/baselines-acktr-a2c/), [PPO](https://blog.openai.com/openai-baselines-ppo/))  
   _(optimization)_  
   _(implementation)_ _(theory)_  
   [Surrogate Loss Functions (blog post)](http://fa.bianp.net/blog/2014/surrogate-loss-functions-in-machine-learning/)  
   [ML for non-differentiable Loss Functions (blog post)](http://khanhxnguyen.com/machine-learning-non-differentiable-loss-functions/)  
   [Comparing Loss Functions by Risk (paper)](http://www.isa.uni-stuttgart.de/Steinwart/Publikationen/2007/Steinwart07a.pdf)  
   [Surrogate Loss Functions and Æ’-divergences (paper)](https://projecteuclid.org/download/pdfview_1/euclid.aos/1236693153)  

---
