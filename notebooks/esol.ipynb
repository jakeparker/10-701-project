{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ESOL Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import deepchem as dc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "def dataset(filename):\n",
    "    DATA_DIR = pathlib.Path('.', 'data')\n",
    "    filepath = DATA_DIR / pathlib.Path(filename)\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = dict()\n",
    "datasets[\"esol\"] = dataset(\"esol.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filepath):\n",
    "    featurizer = dc.feat.CircularFingerprint(size=1024)\n",
    "    loader = dc.data.CSVLoader(tasks=[\"measured log solubility in mols per litre\"], \n",
    "                               smiles_field=\"smiles\",\n",
    "                               featurizer=featurizer)\n",
    "    file = loader.featurize(filepath)\n",
    "    print(file.shape)\n",
    "    return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"esol\"] = load(datasets[\"esol\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(file):\n",
    "    splitter = dc.splits.ScaffoldSplitter(file)\n",
    "    train, valid, test = splitter.train_valid_test_split(file)\n",
    "    return dict(train=train, valid=valid, test=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets[\"esol\"] = split(datasets[\"esol\"], transformers=transformers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transformers(dataset):\n",
    "    transformers = [lambda x: dc.trans.NormalizationTransformer(transform_y=True, \n",
    "                                                                dataset=x)]\n",
    "    transformers = [transformer(dataset) for transformer in transformers]\n",
    "    return transformers\n",
    "\n",
    "def transform(dataset, transformers):   \n",
    "    for key in [\"train\", \"valid\", \"test\"]:\n",
    "        for transformer in transformers:\n",
    "            dataset[key] = transformer.transform(dataset[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers = dict()\n",
    "transformers[\"esolv\"] = transformers(datasets[\"esolv\"][\"train\"])\n",
    "\n",
    "datasets[\"esolv\"] = transform(datasets[\"esolv\"], transformers[\"esolv\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(model, params, dataset, transformers, metric):\n",
    "    optimizer = dc.hyper.HyperparamOpt(model)\n",
    "    optimized = optimizer.hyperparam_search(params,\n",
    "                                            dataset[\"train\"], dataset[\"valid\"],\n",
    "                                            transformers, metric=metric)\n",
    "    return optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from deepchem.utils.evaluate import Evaluator\n",
    "\n",
    "def model(dataset, transformers, metric):\n",
    "    model = dc.models.SklearnModel(RandomForestRegressor(n_estimators=100))\n",
    "    model.fit(dataset[\"train\"])\n",
    "    # evaluator = Evaluator(model.valid_dataset, transformers)\n",
    "    evaluator = Evaluator(model, dataset[\"valid\"], transformers)\n",
    "    r2score = evaluator.compute_model_performance([metric])\n",
    "    return model, evaluator, r2score\n",
    "    \n",
    "def rf_model_builder(model_params, model_dir):\n",
    "    return dc.models.SklearnModel(RandomForestRegressor(**model_params),model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"n_estimators\": [10, 100],\n",
    "    \"max_features\": ['auto', 'sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "metric = dc.metrics.Metric(dc.metrics.r2_score)\n",
    "model, evaluator, r2score = model(datasets[\"esol\"], transformers[\"esol\"], metric)\n",
    "\n",
    "optimized = optimize(rf_model_builder, params, datasets[\"esol\"], transformers[\"esol\"], metric)\n",
    "best_rf, best_rf_hyperparams, all_rf_results = optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multitask Network _(tensorflow)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNselector(model_params, model_dir):\n",
    "    n_features = train_dataset.get_data_shape()[0]\n",
    "    model = dc.models.TensorflowMultiTaskRegressor(\n",
    "        1, n_features, layer_sizes=[1000], dropouts=[.25], batch_size=50,\n",
    "        **model_params)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"learning_rate\": np.power(10.,np.random.uniform(-5,-3,size=1)),\n",
    "    \"decay\": np.power(10,np.random.uniform(-6,-4,size=1)),\n",
    "    \"nb_epoch\": [20]\n",
    "}\n",
    "\n",
    "optimized = optimize(NNselector, params, datasets[\"esol\"], transformers[\"esol\"], metric)\n",
    "best_dnn, best_dnn_hyperparams, all_dnn_results = optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multitask Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NNselector(model_params, model_dir):\n",
    "    n_features = train_dataset.get_data_shape()[0]\n",
    "    model = dc.models.MultiTaskRegressor(\n",
    "        1, n_features, layer_sizes=[1000], dropouts=[.25], batch_size=50,\n",
    "        **model_params)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"learning_rate\": np.power(10., np.random.uniform(-5, -3, size=1)),\n",
    "    \"decay\": np.power(10, np.random.uniform(-6, -4, size=1)),\n",
    "    \"nb_epoch\": [20]\n",
    "}\n",
    "\n",
    "optimized = optimize(NNselector, params, datasets[\"esol\"], transformers[\"esol\"], metric)\n",
    "best_dnn, best_dnn_hyperparams, all_dnn_results = optimized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_test_evaluator = Evaluator(best_rf, datasets[\"esol\"][\"test\"], transformers[\"esol\"])\n",
    "rf_test_r2score = rf_test_evaluator.compute_model_performance([metric])\n",
    "print(\"RF Test set R^2 %f\" % (rf_test_r2score[\"r2_score\"]))\n",
    "\n",
    "task = \"measured log solubility in mols per litre\"\n",
    "predicted_test = best_rf.predict(datasets[\"esol\"][\"test\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
